{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Background\n",
        "\n",
        "### What is Spark?\n",
        "Apache Spark is an open-source, distributed computing framework designed for big data processing. It distributes tasks across multiple nodes, enabling fast, scalable data analysis and machine learning. This is critical for efficiently processing the Heart Failure Prediction dataset.\n",
        "\n",
        "### Why is Spark a popular framework?\n",
        "Spark is popular for its speed (in-memory processing), multi-language support (Python, Scala, Java), and versatility in handling SQL queries, streaming, and ML tasks. Its unified engine simplifies big data workflows, making it ideal for data scientists and engineers.\n",
        "\n",
        "### What is Spark SQL and why does it exist?\n",
        "Spark SQL is a Spark module that allows SQL-like queries on structured DataFrames. It exists to bridge traditional database querying with big data, enabling users familiar with SQL to analyze large datasets seamlessly.\n",
        "\n",
        "### What is a Spark DataFrame, and why is it useful?\n",
        "A Spark DataFrame is a distributed, table-like structure with rows and columns, scalable across clusters. It supports SQL queries, integrates with Spark ML, and optimizes performance, making it perfect for analyzing and modeling the Heart Failure dataset."
      ],
      "metadata": {
        "id": "9ZIHMb8Nsn6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Data Collection\n",
        "\n",
        "**Dataset**: Heart Failure Prediction from Kaggle ([https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)).  \n",
        "**Why Chosen**: This dataset is ideal for binary classification (HeartDisease: 0 = no disease, 1 = disease), with labeled tabular data (12 columns, 918 rows). Its health focus is engaging, and no PySpark solutions exist in Kaggle’s “Code” tab (verified on April 25, 2025).  \n",
        "**Data Fetch**: We fetch `heart.csv` using `!wget` or upload manually to Colab."
      ],
      "metadata": {
        "id": "J1ocZ-ZvssSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "NUgYRLCJsl9b",
        "outputId": "6d140838-1ccd-4b5c-e2a7-93662bd6b7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.11/dist-packages (0.6)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphframes) (2.0.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from graphframes) (1.3.7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8c5318a-7ae3-422c-84d7-7ca5cc15ca58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8c5318a-7ae3-422c-84d7-7ca5cc15ca58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive.zip to archive (1).zip\n",
            "Archive:  archive.zip\n",
            "  inflating: heart.csv               \n",
            "First 5 rows of dataset:\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n",
            "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n",
            "| 37|  M|          ATA|      130|        283|        0|        ST|   98|             N|    0.0|      Up|           0|\n",
            "| 48|  F|          ASY|      138|        214|        0|    Normal|  108|             Y|    1.5|    Flat|           1|\n",
            "| 54|  M|          NAP|      150|        195|        0|    Normal|  122|             N|    0.0|      Up|           0|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and GraphFrames\n",
        "!pip install pyspark graphframes\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session with GraphFrames support\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"HeartFailurePrediction\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.1-s_2.12\") \\\n",
        "     .getOrCreate()\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!unzip -o archive.zip\n",
        "\n",
        "# Load dataset\n",
        "df = spark.read.csv(\"/content/heart.csv\", header=True, inferSchema=True)\n",
        "print(\"First 5 rows of dataset:\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n",
        "\n",
        "We use Spark SQL to check for duplicates, null values, type inconsistencies, misspellings, and outliers. All checks are shown to verify data quality, even if no changes are needed. The cleaned data is saved and reloaded for further analysis."
      ],
      "metadata": {
        "id": "WvGsqtl_tTc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required functions\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "DUXlOf52tVSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Duplicates\n",
        "We check for duplicate rows and remove them if present."
      ],
      "metadata": {
        "id": "QYLGhIG1tbXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates\n",
        "total_rows = df.count()\n",
        "unique_rows = df.dropDuplicates().count()\n",
        "print(f\"Total rows: {total_rows}, Unique rows: {unique_rows}, Duplicates: {total_rows - unique_rows}\")\n",
        "if total_rows != unique_rows:\n",
        "    df = df.dropDuplicates()\n",
        "    print(\"Duplicates dropped.\")\n",
        "else:\n",
        "    print(\"No duplicates found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGVAWxITtcR_",
        "outputId": "fbab9d0e-c055-45d7-a2d1-6bb5c200c727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 918, Unique rows: 918, Duplicates: 0\n",
            "No duplicates found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Null Values\n",
        "We verify no null values exist, filling with means if needed (unlikely for this dataset)."
      ],
      "metadata": {
        "id": "FVQDih2EthnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values\n",
        "print(\"Null values per column:\")\n",
        "df.select([col(c).isNull().cast(\"int\").alias(c) for c in df.columns]).agg(*[F.sum(c).alias(c) for c in df.columns]).show()\n",
        "if df.filter(col(\"Cholesterol\").isNull()).count() > 0:\n",
        "    chol_mean = df.select(\"Cholesterol\").agg({\"Cholesterol\": \"mean\"}).collect()[0][0]\n",
        "    df = df.fillna({\"Cholesterol\": chol_mean})\n",
        "    print(\"Filled nulls in Cholesterol with mean.\")\n",
        "else:\n",
        "    print(\"No nulls found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eML58VvJtiO6",
        "outputId": "69e7efa7-b261-4ba7-fc8f-732a04746b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null values per column:\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "|  0|  0|            0|        0|          0|        0|         0|    0|             0|      0|       0|           0|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "\n",
            "No nulls found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type Inconsistency\n",
        "We confirm correct data types (e.g., strings for categorical, integers/doubles for numeric) and cast if necessary."
      ],
      "metadata": {
        "id": "oZxv_ht9tmgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data types\n",
        "print(\"Schema to verify data types:\")\n",
        "df.printSchema()\n",
        "df = df.withColumn(\"Sex\", col(\"Sex\").cast(\"string\")).withColumn(\"ChestPainType\", col(\"ChestPainType\").cast(\"string\"))\n",
        "print(\"Verified/corrected types (Sex and ChestPainType cast to string).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_q4_LstnCC",
        "outputId": "a88d2040-2fcc-435b-85dd-9ac9235441c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema to verify data types:\n",
            "root\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- ChestPainType: string (nullable = true)\n",
            " |-- RestingBP: integer (nullable = true)\n",
            " |-- Cholesterol: integer (nullable = true)\n",
            " |-- FastingBS: integer (nullable = true)\n",
            " |-- RestingECG: string (nullable = true)\n",
            " |-- MaxHR: integer (nullable = true)\n",
            " |-- ExerciseAngina: string (nullable = true)\n",
            " |-- Oldpeak: double (nullable = true)\n",
            " |-- ST_Slope: string (nullable = true)\n",
            " |-- HeartDisease: integer (nullable = true)\n",
            "\n",
            "Verified/corrected types (Sex and ChestPainType cast to string).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Misspellings/Mistypings\n",
        "We check categorical columns for invalid values and filter out any anomalies."
      ],
      "metadata": {
        "id": "lAT7sTVktsbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check categorical columns for invalid values\n",
        "print(\"Checking categorical columns for misspellings:\")\n",
        "for cat_col in [\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\"]:\n",
        "    print(f\"Values in {cat_col}:\")\n",
        "    df.groupBy(cat_col).count().show()\n",
        "valid_types = [\"ASY\", \"NAP\", \"ATA\", \"TA\"]\n",
        "df = df.filter(col(\"ChestPainType\").isin(valid_types))\n",
        "print(\"Verified/corrected categorical values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j39E2gH6ttP2",
        "outputId": "8f705851-0acf-4c8b-8497-59119b285b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking categorical columns for misspellings:\n",
            "Values in Sex:\n",
            "+---+-----+\n",
            "|Sex|count|\n",
            "+---+-----+\n",
            "|  F|  193|\n",
            "|  M|  725|\n",
            "+---+-----+\n",
            "\n",
            "Values in ChestPainType:\n",
            "+-------------+-----+\n",
            "|ChestPainType|count|\n",
            "+-------------+-----+\n",
            "|          NAP|  203|\n",
            "|          ATA|  173|\n",
            "|           TA|   46|\n",
            "|          ASY|  496|\n",
            "+-------------+-----+\n",
            "\n",
            "Values in RestingECG:\n",
            "+----------+-----+\n",
            "|RestingECG|count|\n",
            "+----------+-----+\n",
            "|       LVH|  188|\n",
            "|    Normal|  552|\n",
            "|        ST|  178|\n",
            "+----------+-----+\n",
            "\n",
            "Values in ExerciseAngina:\n",
            "+--------------+-----+\n",
            "|ExerciseAngina|count|\n",
            "+--------------+-----+\n",
            "|             Y|  371|\n",
            "|             N|  547|\n",
            "+--------------+-----+\n",
            "\n",
            "Values in ST_Slope:\n",
            "+--------+-----+\n",
            "|ST_Slope|count|\n",
            "+--------+-----+\n",
            "|    Flat|  460|\n",
            "|      Up|  395|\n",
            "|    Down|   63|\n",
            "+--------+-----+\n",
            "\n",
            "Verified/corrected categorical values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outliers\n",
        "We identify outliers in numeric columns using IQR and remove them to ensure robust ML performance."
      ],
      "metadata": {
        "id": "PYqrhqNetyBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for outliers with summary stats\n",
        "print(\"Checking for outliers:\")\n",
        "df.describe([\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\"]).show()\n",
        "q1, q3 = df.approxQuantile(\"Cholesterol\", [0.25, 0.75], 0.05)\n",
        "iqr = q3 - q1\n",
        "df = df.filter((col(\"Cholesterol\") >= q1 - 1.5 * iqr) & (col(\"Cholesterol\") <= q3 + 1.5 * iqr))\n",
        "print(\"Removed outliers in Cholesterol using IQR method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4VLMkyPtyfi",
        "outputId": "47f81ded-5968-450b-d33c-38263ea13f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for outliers:\n",
            "+-------+------------------+------------------+------------------+------------------+\n",
            "|summary|               Age|         RestingBP|       Cholesterol|             MaxHR|\n",
            "+-------+------------------+------------------+------------------+------------------+\n",
            "|  count|               918|               918|               918|               918|\n",
            "|   mean|53.510893246187365|132.39651416122004| 198.7995642701525|136.80936819172112|\n",
            "| stddev|  9.43261650673202|18.514154119907808|109.38414455220345| 25.46033413825029|\n",
            "|    min|                28|                 0|                 0|                60|\n",
            "|    max|                77|               200|               603|               202|\n",
            "+-------+------------------+------------------+------------------+------------------+\n",
            "\n",
            "Removed outliers in Cholesterol using IQR method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# List of numeric columns to check outliers\n",
        "numeric_cols = [\"Age\", \"RestingBP\", \"MaxHR\", \"Oldpeak\", \"FastingBS\"]\n",
        "\n",
        "# Loop through each numeric column\n",
        "for column in numeric_cols:\n",
        "    print(f\"\\nChecking outliers for {column}:\")\n",
        "    # Describe stats\n",
        "    df_cleaned.describe([column]).show()\n",
        "    # IQR method\n",
        "    q1, q3 = df_cleaned.approxQuantile(column, [0.25, 0.75], 0.05)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    outliers = df_cleaned.filter((col(column) < lower_bound) | (col(column) > upper_bound))\n",
        "    outlier_count = outliers.count()\n",
        "    print(f\"Found {outlier_count} outliers in {column}.\")\n",
        "    if outlier_count > 0:\n",
        "        df_cleaned = df_cleaned.filter((col(column) >= lower_bound) & (col(column) <= upper_bound))\n",
        "        print(f\"Removed outliers from {column}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERADkbFOtg0t",
        "outputId": "c9d060d2-c220-4bf6-e381-6484cf255183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking outliers for Age:\n",
            "+-------+-----------------+\n",
            "|summary|              Age|\n",
            "+-------+-----------------+\n",
            "|  count|              910|\n",
            "|   mean|53.54065934065934|\n",
            "| stddev|9.419334772243241|\n",
            "|    min|               28|\n",
            "|    max|               77|\n",
            "+-------+-----------------+\n",
            "\n",
            "Found 1 outliers in Age.\n",
            "Removed outliers from Age.\n",
            "\n",
            "Checking outliers for RestingBP:\n",
            "+-------+------------------+\n",
            "|summary|         RestingBP|\n",
            "+-------+------------------+\n",
            "|  count|               909|\n",
            "|   mean|132.45544554455446|\n",
            "| stddev|18.569533736711016|\n",
            "|    min|                 0|\n",
            "|    max|               200|\n",
            "+-------+------------------+\n",
            "\n",
            "Found 28 outliers in RestingBP.\n",
            "Removed outliers from RestingBP.\n",
            "\n",
            "Checking outliers for MaxHR:\n",
            "+-------+------------------+\n",
            "|summary|             MaxHR|\n",
            "+-------+------------------+\n",
            "|  count|               881|\n",
            "|   mean|136.95005675368898|\n",
            "| stddev| 25.30877054449797|\n",
            "|    min|                60|\n",
            "|    max|               202|\n",
            "+-------+------------------+\n",
            "\n",
            "Found 2 outliers in MaxHR.\n",
            "Removed outliers from MaxHR.\n",
            "\n",
            "Checking outliers for Oldpeak:\n",
            "+-------+------------------+\n",
            "|summary|           Oldpeak|\n",
            "+-------+------------------+\n",
            "|  count|               879|\n",
            "|   mean|0.8841865756541525|\n",
            "| stddev|1.0649254807265507|\n",
            "|    min|              -2.6|\n",
            "|    max|               6.2|\n",
            "+-------+------------------+\n",
            "\n",
            "Found 21 outliers in Oldpeak.\n",
            "Removed outliers from Oldpeak.\n",
            "\n",
            "Checking outliers for FastingBS:\n",
            "+-------+-------------------+\n",
            "|summary|          FastingBS|\n",
            "+-------+-------------------+\n",
            "|  count|                858|\n",
            "|   mean|0.23193473193473194|\n",
            "| stddev| 0.4223137197417737|\n",
            "|    min|                  0|\n",
            "|    max|                  1|\n",
            "+-------+-------------------+\n",
            "\n",
            "Found 199 outliers in FastingBS.\n",
            "Removed outliers from FastingBS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and reload\n",
        "df.write.csv(\"/content/cleaned_heart.csv\", header=True, mode=\"overwrite\")\n",
        "df_cleaned = spark.read.csv(\"/content/cleaned_heart.csv\", header=True, inferSchema=True)\n",
        "print(\"Saved and reloaded cleaned data.\")\n",
        "print(\"First 5 rows of cleaned dataset:\")\n",
        "df_cleaned.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Y1sE02t4Rz",
        "outputId": "501fec45-5428-47ee-b94f-8d8516fca934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved and reloaded cleaned data.\n",
            "First 5 rows of cleaned dataset:\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n",
            "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n",
            "| 37|  M|          ATA|      130|        283|        0|        ST|   98|             N|    0.0|      Up|           0|\n",
            "| 48|  F|          ASY|      138|        214|        0|    Normal|  108|             Y|    1.5|    Flat|           1|\n",
            "| 54|  M|          NAP|      150|        195|        0|    Normal|  122|             N|    0.0|      Up|           0|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "We explore the cleaned dataset using Spark SQL to understand its schema, shape, statistics, column distributions, and correlations. This informs feature selection for machine learning."
      ],
      "metadata": {
        "id": "FSMXH21Xt7W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema\n",
        "print(\"Dataset schema:\")\n",
        "df_cleaned.printSchema()\n",
        "print(\"Columns and Types:\", [(col, dtype) for col, dtype in df_cleaned.dtypes])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB7wDoIJt8Kn",
        "outputId": "28bf7609-1128-49f6-db5f-14df4ce56210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset schema:\n",
            "root\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- ChestPainType: string (nullable = true)\n",
            " |-- RestingBP: integer (nullable = true)\n",
            " |-- Cholesterol: integer (nullable = true)\n",
            " |-- FastingBS: integer (nullable = true)\n",
            " |-- RestingECG: string (nullable = true)\n",
            " |-- MaxHR: integer (nullable = true)\n",
            " |-- ExerciseAngina: string (nullable = true)\n",
            " |-- Oldpeak: double (nullable = true)\n",
            " |-- ST_Slope: string (nullable = true)\n",
            " |-- HeartDisease: integer (nullable = true)\n",
            "\n",
            "Columns and Types: [('Age', 'int'), ('Sex', 'string'), ('ChestPainType', 'string'), ('RestingBP', 'int'), ('Cholesterol', 'int'), ('FastingBS', 'int'), ('RestingECG', 'string'), ('MaxHR', 'int'), ('ExerciseAngina', 'string'), ('Oldpeak', 'double'), ('ST_Slope', 'string'), ('HeartDisease', 'int')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shape\n",
        "rows = df_cleaned.count()\n",
        "cols = len(df_cleaned.columns)\n",
        "print(f\"Shape: {rows} rows, {cols} columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__tAhXEfuIpH",
        "outputId": "cde85fe7-c02c-4dd4-f70a-c4baa1e215b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: 910 rows, 12 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show summary statistics\n",
        "print(\"Summary statistics:\")\n",
        "# Full summary statistics (no truncation)\n",
        "df_cleaned.describe().show(1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoOl4qZiuLsw",
        "outputId": "a223d600-16f9-471b-fb10-12644f238cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary statistics:\n",
            "+-------+-----------------+----+-------------+------------------+-----------------+---------+----------+------------------+--------------+------------------+--------+-------------------+\n",
            "|summary|              Age| Sex|ChestPainType|         RestingBP|      Cholesterol|FastingBS|RestingECG|             MaxHR|ExerciseAngina|           Oldpeak|ST_Slope|       HeartDisease|\n",
            "+-------+-----------------+----+-------------+------------------+-----------------+---------+----------+------------------+--------------+------------------+--------+-------------------+\n",
            "|  count|              659| 659|          659|               659|              659|      659|       659|               659|           659|               659|     659|                659|\n",
            "|   mean| 52.3247344461305|NULL|         NULL|130.56904400606982|212.3990895295903|      0.0|      NULL|139.06069802731412|          NULL|0.7667678300455234|    NULL|  0.464339908952959|\n",
            "| stddev|9.484470335814981|NULL|         NULL|15.288393222368683|90.68102718969888|      0.0|      NULL|24.813455147377685|          NULL|0.9261009348099813|    NULL|0.49910556451463767|\n",
            "|    min|               29|   F|          ASY|                92|                0|        0|       LVH|                71|             N|              -1.1|    Down|                  0|\n",
            "|    max|               77|   M|           TA|               170|              412|        0|        ST|               202|             Y|               3.4|      Up|                  1|\n",
            "+-------+-----------------+----+-------------+------------------+-----------------+---------+----------+------------------+--------------+------------------+--------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column Analysis\n",
        "We analyze 7 key columns: their real-world meaning, units, distribution, and why the distribution is useful.\n",
        "- **Age**: Patient’s age in years (numeric). Distribution shows age range, aiding risk profiling.\n",
        "- **Sex**: Biological sex (M/F, categorical). Distribution reveals gender balance, useful for gender-based risk analysis.\n",
        "- **ChestPainType**: Type of chest pain (ASY/NAP/ATA/TA, categorical). Distribution indicates symptom prevalence, critical for diagnosis.\n",
        "- **RestingBP**: Resting blood pressure in mmHg (numeric). Distribution identifies typical values, with outliers signaling risk.\n",
        "- **Cholesterol**: Serum cholesterol in mg/dl (numeric). Skewed distribution highlights high-risk patients.\n",
        "- **MaxHR**: Maximum heart rate achieved (numeric). Distribution and correlation with disease guide feature selection.\n",
        "- **ExerciseAngina**: Exercise-induced angina (Y/N, categorical). Distribution predicts disease likelihood, improving model accuracy."
      ],
      "metadata": {
        "id": "IkYvSdZ-uPiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze distributions\n",
        "print(\"### Column Analysis\")\n",
        "columns = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"ExerciseAngina\"]\n",
        "for col_name in columns:\n",
        "    print(f\"Distribution of {col_name}:\")\n",
        "    if col_name in [\"Sex\", \"ChestPainType\", \"ExerciseAngina\"]:\n",
        "        df_cleaned.groupBy(col_name).count().show()\n",
        "    else:\n",
        "        df_cleaned.select(col_name).summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Pzysr4uPOm",
        "outputId": "1bb522a3-49d8-4ff8-d3f7-1ea9a547ed44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Column Analysis\n",
            "Distribution of Age:\n",
            "+-------+-----------------+\n",
            "|summary|              Age|\n",
            "+-------+-----------------+\n",
            "|  count|              910|\n",
            "|   mean|53.54065934065934|\n",
            "| stddev|9.419334772243241|\n",
            "|    min|               28|\n",
            "|    25%|               47|\n",
            "|    50%|               54|\n",
            "|    75%|               60|\n",
            "|    max|               77|\n",
            "+-------+-----------------+\n",
            "\n",
            "Distribution of Sex:\n",
            "+---+-----+\n",
            "|Sex|count|\n",
            "+---+-----+\n",
            "|  F|  191|\n",
            "|  M|  719|\n",
            "+---+-----+\n",
            "\n",
            "Distribution of ChestPainType:\n",
            "+-------------+-----+\n",
            "|ChestPainType|count|\n",
            "+-------------+-----+\n",
            "|          NAP|  201|\n",
            "|          ATA|  172|\n",
            "|           TA|   46|\n",
            "|          ASY|  491|\n",
            "+-------------+-----+\n",
            "\n",
            "Distribution of RestingBP:\n",
            "+-------+------------------+\n",
            "|summary|         RestingBP|\n",
            "+-------+------------------+\n",
            "|  count|               910|\n",
            "|   mean|132.45274725274726|\n",
            "| stddev|18.559495155609646|\n",
            "|    min|                 0|\n",
            "|    25%|               120|\n",
            "|    50%|               130|\n",
            "|    75%|               140|\n",
            "|    max|               200|\n",
            "+-------+------------------+\n",
            "\n",
            "Distribution of Cholesterol:\n",
            "+-------+------------------+\n",
            "|summary|       Cholesterol|\n",
            "+-------+------------------+\n",
            "|  count|               910|\n",
            "|   mean|196.04505494505494|\n",
            "| stddev| 105.7260463069945|\n",
            "|    min|                 0|\n",
            "|    25%|               172|\n",
            "|    50%|               222|\n",
            "|    75%|               266|\n",
            "|    max|               417|\n",
            "+-------+------------------+\n",
            "\n",
            "Distribution of MaxHR:\n",
            "+-------+-----------------+\n",
            "|summary|            MaxHR|\n",
            "+-------+-----------------+\n",
            "|  count|              910|\n",
            "|   mean|136.8824175824176|\n",
            "| stddev|25.44915374805419|\n",
            "|    min|               60|\n",
            "|    25%|              120|\n",
            "|    50%|              138|\n",
            "|    75%|              156|\n",
            "|    max|              202|\n",
            "+-------+-----------------+\n",
            "\n",
            "Distribution of ExerciseAngina:\n",
            "+--------------+-----+\n",
            "|ExerciseAngina|count|\n",
            "+--------------+-----+\n",
            "|             Y|  369|\n",
            "|             N|  541|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Register DataFrame as SQL table\n",
        "df_cleaned.createOrReplaceTempView(\"heart\")\n",
        "print(\"Sex distribution via SQL:\")\n",
        "spark.sql(\"SELECT Sex, COUNT(*) as count FROM heart GROUP BY Sex\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJs5JyyWuWcC",
        "outputId": "f7b3209e-f88d-4daf-adcc-37e26748417f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sex distribution via SQL:\n",
            "+---+-----+\n",
            "|Sex|count|\n",
            "+---+-----+\n",
            "|  F|  191|\n",
            "|  M|  719|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Analysis\n",
        "We compute correlations between `Age`, `Cholesterol`, `MaxHR`, and `HeartDisease` to identify predictive features.\n",
        "- **Age (e.g., 0.28)**: Older age moderately increases risk, useful for profiling.\n",
        "- **Cholesterol (e.g., 0.23)**: Weak correlation, not a dominant predictor.\n",
        "- **MaxHR (e.g., -0.40)**: Lower heart rates strongly predict disease, a key ML feature."
      ],
      "metadata": {
        "id": "sP6xnWnwuY6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "from pyspark.sql.functions import corr\n",
        "print(\"### Correlation Analysis\")\n",
        "for col_name in [\"Age\", \"Cholesterol\", \"MaxHR\"]:\n",
        "    corr_value = df_cleaned.select(corr(col_name, \"HeartDisease\")).collect()[0][0]\n",
        "    print(f\"Correlation between {col_name} and HeartDisease: {corr_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOvWgCQjuZ1L",
        "outputId": "ef0a54c7-0ad7-495c-e902-eca51a8ff5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Correlation Analysis\n",
            "Correlation between Age and HeartDisease: 0.29182691694934043\n",
            "Correlation between Cholesterol and HeartDisease: -0.2476366345921841\n",
            "Correlation between MaxHR and HeartDisease: -0.40621172405561623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning\n",
        "\n",
        "We apply LogisticRegression for binary classification to predict `HeartDisease` (0 = no disease, 1 = disease). LogisticRegression fits a logistic function to predict probabilities, ideal for binary outcomes due to its interpretability and effectiveness."
      ],
      "metadata": {
        "id": "l7Mo_Rb6ufmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML libraries\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "bXZoCMR2ugT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n",
        "We index categorical columns and assemble features into a vector."
      ],
      "metadata": {
        "id": "WrWdzsHCukOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index categorical columns\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\"),\n",
        "    StringIndexer(inputCol=\"ChestPainType\", outputCol=\"ChestPainTypeIndex\"),\n",
        "    StringIndexer(inputCol=\"RestingECG\", outputCol=\"RestingECGIndex\"),\n",
        "    StringIndexer(inputCol=\"ExerciseAngina\", outputCol=\"ExerciseAnginaIndex\"),\n",
        "    StringIndexer(inputCol=\"ST_Slope\", outputCol=\"ST_SlopeIndex\")\n",
        "]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df_indexed = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"Age\", \"SexIndex\", \"ChestPainTypeIndex\", \"RestingBP\",\n",
        "        \"Cholesterol\", \"FastingBS\", \"RestingECGIndex\", \"MaxHR\",\n",
        "        \"ExerciseAnginaIndex\", \"Oldpeak\", \"ST_SlopeIndex\"\n",
        "    ],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_final = assembler.transform(df_indexed)\n",
        "final_data = df_final.select(\"features\", \"HeartDisease\")\n",
        "print(\"Sample prepared data:\")\n",
        "final_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hptnRp_QulHk",
        "outputId": "c6f85f4e-f672-4ffd-f740-ee033da8c553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample prepared data:\n",
            "+--------------------+------------+\n",
            "|            features|HeartDisease|\n",
            "+--------------------+------------+\n",
            "|(11,[0,2,3,4,7,10...|           0|\n",
            "|[49.0,1.0,1.0,160...|           1|\n",
            "|[37.0,0.0,2.0,130...|           0|\n",
            "|[48.0,1.0,0.0,138...|           1|\n",
            "|(11,[0,2,3,4,7,10...|           0|\n",
            "+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split\n",
        "We split data into 80% training and 20% testing."
      ],
      "metadata": {
        "id": "CWKwbPn5up5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
        "print(f\"Training set size: {train_data.count()}\")\n",
        "print(f\"Testing set size: {test_data.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfx8T6OCuq2H",
        "outputId": "6a2439c5-68c6-4773-d4b3-57874925c471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 762\n",
            "Testing set size: 148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "We train LogisticRegression on the training data."
      ],
      "metadata": {
        "id": "iEnw8Qa_uvYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LogisticRegression\n",
        "lr = LogisticRegression(labelCol=\"HeartDisease\", featuresCol=\"features\")\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "5utY3BpHuwD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions\n",
        "We predict on the test data and show sample results."
      ],
      "metadata": {
        "id": "aKC3Kf_Uu8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "test_results = lr_model.transform(test_data)\n",
        "print(\"Sample predictions:\")\n",
        "test_results.select(\"HeartDisease\", \"prediction\", \"probability\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVEGeTG7u3_4",
        "outputId": "f27d89b9-f95f-4f5f-be8f-2be3de6c4450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample predictions:\n",
            "+------------+----------+--------------------+\n",
            "|HeartDisease|prediction|         probability|\n",
            "+------------+----------+--------------------+\n",
            "|           0|       0.0|[0.91575074924559...|\n",
            "|           1|       1.0|[0.39158630223721...|\n",
            "|           0|       0.0|[0.53564824027045...|\n",
            "|           0|       0.0|[0.88750777131844...|\n",
            "|           1|       1.0|[0.09286476473808...|\n",
            "+------------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "We evaluate with:\n",
        "- **AUC**: Measures ability to distinguish classes (closer to 1 is better).\n",
        "- **Accuracy**: Fraction of correct predictions.\n",
        "- **F1-score**: Balances precision and recall, robust for imbalanced data.\n",
        "\n",
        "**Results**: High AUC (e.g., 0.925) indicates strong discriminative power. Accuracy and F1-score confirm reliability, with `MaxHR` and `Age` as key features."
      ],
      "metadata": {
        "id": "izOhTMHqvBTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "auc_evaluator = BinaryClassificationEvaluator(labelCol=\"HeartDisease\", rawPredictionCol=\"rawPrediction\")\n",
        "auc = auc_evaluator.evaluate(test_results)\n",
        "print(\"Test AUC (Area under ROC):\", auc)\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = acc_evaluator.evaluate(test_results)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = f1_evaluator.evaluate(test_results)\n",
        "print(\"Test F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXGKt4wrvCEm",
        "outputId": "699fc92d-72d6-4dc7-ffd2-728f7aac5f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC (Area under ROC): 0.9346991037131881\n",
            "Test Accuracy: 0.8581081081081081\n",
            "Test F1-score: 0.8581664331607239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GraphFrames\n",
        "from graphframes import GraphFrame"
      ],
      "metadata": {
        "id": "conu5weyvH_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample graph\n",
        "nodes = spark.createDataFrame([\n",
        "    (\"1\", \"Alice\", 25),\n",
        "    (\"2\", \"Bob\", 30),\n",
        "    (\"3\", \"Charlie\", 28),\n",
        "    (\"4\", \"Diana\", 27)\n",
        "], [\"id\", \"name\", \"age\"])\n",
        "edges = spark.createDataFrame([\n",
        "    (\"1\", \"2\", \"friend\"),\n",
        "    (\"2\", \"3\", \"friend\"),\n",
        "    (\"3\", \"4\", \"friend\"),\n",
        "    (\"4\", \"1\", \"friend\")\n",
        "], [\"src\", \"dst\", \"relationship\"])\n",
        "graph = GraphFrame(nodes, edges)\n"
      ],
      "metadata": {
        "id": "eFg5bA4avMFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600946e1-1a5b-468a-c90c-e1db2b6403d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interesting insight: Node degrees\n",
        "print(\"Degree of nodes (number of friends):\")\n",
        "graph.degrees.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOgJrUM_vTZA",
        "outputId": "4079dd2e-cfe4-439c-d3d1-d61dc7d4dbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree of nodes (number of friends):\n",
            "+---+------+\n",
            "| id|degree|\n",
            "+---+------+\n",
            "|  3|     2|\n",
            "|  1|     2|\n",
            "|  2|     2|\n",
            "|  4|     2|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GraphFrames package\n",
        "!pip install graphframes\n",
        "\n",
        "# Restart runtime if asked. Then re-import SparkSession:\n",
        "from pyspark.sql import SparkSession\n",
        "from graphframes import GraphFrame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO6kUPwIvtmt",
        "outputId": "d557b991-4cdc-44d8-bc09-3ba686b7b36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.11/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphframes) (2.0.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from graphframes) (1.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vertices (nodes) - each patient with ID, Name, and Heart Disease Status\n",
        "vertices = spark.createDataFrame([\n",
        "    (\"1\", \"PatientA\", 1),\n",
        "    (\"2\", \"PatientB\", 0),\n",
        "    (\"3\", \"PatientC\", 1),\n",
        "    (\"4\", \"PatientD\", 0)\n",
        "], [\"id\", \"name\", \"HeartDisease\"])\n",
        "\n",
        "# Create edges (relationships between patients)\n",
        "edges = spark.createDataFrame([\n",
        "    (\"1\", \"2\", \"friend\"),\n",
        "    (\"2\", \"3\", \"friend\"),\n",
        "    (\"3\", \"4\", \"friend\"),\n",
        "    (\"4\", \"1\", \"friend\")\n",
        "], [\"src\", \"dst\", \"relationship\"])\n",
        "\n",
        "# Build GraphFrame\n",
        "g = GraphFrame(vertices, edges)\n"
      ],
      "metadata": {
        "id": "atwSQCa9vw_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show vertices (nodes)\n",
        "print(\"Vertices (Patients):\")\n",
        "g.vertices.show()\n",
        "\n",
        "# Show edges (connections)\n",
        "print(\"Edges (Relationships):\")\n",
        "g.edges.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78A5lPQpv3pv",
        "outputId": "55606250-7d0f-4a5c-e3aa-f19b8dd90c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertices (Patients):\n",
            "+---+--------+------------+\n",
            "| id|    name|HeartDisease|\n",
            "+---+--------+------------+\n",
            "|  1|PatientA|           1|\n",
            "|  2|PatientB|           0|\n",
            "|  3|PatientC|           1|\n",
            "|  4|PatientD|           0|\n",
            "+---+--------+------------+\n",
            "\n",
            "Edges (Relationships):\n",
            "+---+---+------------+\n",
            "|src|dst|relationship|\n",
            "+---+---+------------+\n",
            "|  1|  2|      friend|\n",
            "|  2|  3|      friend|\n",
            "|  3|  4|      friend|\n",
            "|  4|  1|      friend|\n",
            "+---+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of vertices (patients)\n",
        "print(\"Number of vertices:\", g.vertices.count())\n",
        "\n",
        "# Number of edges (connections)\n",
        "print(\"Number of edges:\", g.edges.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gODIm3QFv5dr",
        "outputId": "6f55ac1c-9c65-4016-c12b-c0a01f4d4abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 4\n",
            "Number of edges: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all patients who are connected and have Heart Disease = 1\n",
        "print(\"Connections starting from patients with Heart Disease:\")\n",
        "g.find(\"(a)-[e]->(b)\").filter(\"a.HeartDisease == 1\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kJRt3tEwBoJ",
        "outputId": "99ccc46f-3b4e-47b2-c9bd-5958761530ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connections starting from patients with Heart Disease:\n",
            "+----------------+--------------+----------------+\n",
            "|               a|             e|               b|\n",
            "+----------------+--------------+----------------+\n",
            "|{1, PatientA, 1}|{1, 2, friend}|{2, PatientB, 0}|\n",
            "|{3, PatientC, 1}|{3, 4, friend}|{4, PatientD, 0}|\n",
            "+----------------+--------------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}